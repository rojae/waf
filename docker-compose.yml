version: "3.8"

services:
  # Nginx + ModSecurity
  nginx:
    build: .
    container_name: waf-nginx
    ports:
      - "8080:80"
    volumes:
      - modsec-logs:/var/log/modsecurity
      - ./nginx/modsecurity/rules:/etc/modsecurity/rules:ro
      - ./nginx/modsecurity/custom-whitelist.conf:/etc/modsecurity/custom-whitelist.conf:ro
      - custom-rules-volume:/etc/modsecurity/custom-rules
    # depends_on:
    #   - waf-dashboard-api

  # Kafka (KRaft mode)
  kafka:
    image: confluentinc/cp-kafka:7.6.1
    container_name: waf-kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_NODE_ID: 1
      # 9092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
      # "kafka:9092"
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_LOG_DIRS: /tmp/kraft-combined-logs
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      CLUSTER_ID: q1w2e3r4t5y6u7i8o9p0aa

    healthcheck:
      test: ["CMD", "bash", "-lc", "kafka-broker-api-versions --bootstrap-server localhost:9092 >/dev/null 2>&1"]
      interval: 5s
      timeout: 5s
      retries: 30

  # kafka:
  #   image: confluentinc/cp-kafka:7.6.1
  #   container_name: waf-kafka
  #   ports:
  #     - "9092:9092"
  #   environment:
  #     KAFKA_PROCESS_ROLES: broker,controller
  #     KAFKA_NODE_ID: 1
  #     KAFKA_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:9093
  #     KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
  #     KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
  #     KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
  #     KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
  #     KAFKA_LOG_DIRS: /tmp/kraft-combined-logs
  #     KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
  #     KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
  #     KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
  #     CLUSTER_ID: q1w2e3r4t5y6u7i8o9p0aa
  #   healthcheck:
  #     test: ["CMD", "bash", "-lc", "kafka-broker-api-versions --bootstrap-server localhost:9092 >/dev/null 2>&1"]
  #     interval: 5s
  #     timeout: 5s
  #     retries: 30

  topics-init:
    image: confluentinc/cp-kafka:7.6.1
    depends_on:
      kafka:
        condition: service_healthy
    restart: "no"
    environment:
      BROKER: "kafka:9092"
    volumes:
      - ./kafka/ensure-topics.sh:/scripts/ensure-topics.sh:ro
    entrypoint: ["/bin/bash","-lc","/scripts/ensure-topics.sh"]

  # ksqlDB Server
  ksqldb:
    image: confluentinc/cp-ksqldb-server:7.6.6
    container_name: waf-ksqldb
    ports:
      - "8088:8088"
    environment:
      KSQL_BOOTSTRAP_SERVERS: "kafka:9092"
      KSQL_LISTENERS: "http://0.0.0.0:8088"
      KSQL_KSQL_SERVICE_ID: "waf_ksqldb_01"
      KSQL_KSQL_STREAMS_REPLICATION_FACTOR: "1"
      KSQL_KSQL_INTERNAL_TOPIC_REPLICAS: "1"
      KSQL_KSQL_SINK_REPLICAS: "1"
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_REPLICATION_FACTOR: "1"
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: "true"
      KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: "true"
      KSQL_KSQL_STREAMS_AUTO_OFFSET_RESET: "earliest"
      KSQL_HEAP_OPTS: "-Xms512m -Xmx512m"
      KSQL_KSQL_STREAMS_NUM_STANDBY_REPLICAS: "0"
    depends_on:
      kafka:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:8088/info >/dev/null 2>&1"]
      interval: 5s
      timeout: 5s
      retries: 60
      start_period: 10s

  ksqldb-cli-init:
    image: confluentinc/cp-ksqldb-cli:7.6.6
    depends_on:
      ksqldb:
        condition: service_healthy
    volumes:
      - ./ksqldb/ddl.sql:/scripts/ddl.sql:ro
      - ./ksqldb/init-ksqldb.sh:/scripts/init-ksqldb.sh:ro
    environment:
      - KSQLDB_URL=http://waf-ksqldb:8088
    entrypoint: ["/scripts/init-ksqldb.sh"]
    restart: on-failure:3

  # Elasticsearch
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.15.2
    container_name: waf-es
    ports:
      - "9200:9200"
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - xpack.ml.enabled=false
      - ingest.geoip.downloader.enabled=false
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
    volumes:
      - es-data:/usr/share/elasticsearch/data
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Kibana
  kibana:
    image: docker.elastic.co/kibana/kibana:8.15.2
    container_name: waf-kibana
    depends_on: 
      elasticsearch:
        condition: service_healthy
    environment:
      - ELASTICSEARCH_HOSTS=http://waf-es:9200
    ports:
      - "5601:5601"
      
  # Logstash
  logstash:
    image: docker.elastic.co/logstash/logstash:8.15.2
    container_name: waf-logstash
    depends_on:
      - elasticsearch
      - kafka
    volumes:
      - ./logstash/pipeline:/usr/share/logstash/pipeline:ro
    environment:
      - LS_JAVA_OPTS=-Xms512m -Xmx512m

  # Fluent Bit
  fluent-bit:
    image: fluent/fluent-bit:2.2
    container_name: waf-fluent-bit
    depends_on:
      nginx:
        condition: service_started
      kafka:
        condition: service_healthy
    volumes:
      - modsec-logs:/var/log/modsecurity:ro
      - ./fluent-bit/fluent-bit.conf:/fluent-bit/etc/fluent-bit.conf:ro
      - ./fluent-bit/parsers.conf:/fluent-bit/etc/parsers.conf:ro
      - ./fluent-bit/waf_classifier.lua:/fluent-bit/etc/waf_classifier.lua:ro
    command: ["/fluent-bit/bin/fluent-bit", "-c", "/fluent-bit/etc/fluent-bit.conf"]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:2020/api/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # InfluxDB for real-time metrics
  influxdb:
    image: influxdb:2.7-alpine
    container_name: waf-influxdb
    ports:
      - "8086:8086"
    environment:
      - DOCKER_INFLUXDB_INIT_MODE=setup
      - DOCKER_INFLUXDB_INIT_USERNAME=admin
      - DOCKER_INFLUXDB_INIT_PASSWORD=adminpassword
      - DOCKER_INFLUXDB_INIT_ORG=waf-org
      - DOCKER_INFLUXDB_INIT_BUCKET=waf-realtime
      - DOCKER_INFLUXDB_INIT_RETENTION=7d
    volumes:
      - influxdb-data:/var/lib/influxdb2
    healthcheck:
      test: ["CMD", "influx", "ping"]
      interval: 10s
      timeout: 5s
      retries: 30

  # Real-time processor
  realtime-processor:
    build: ./services/realtime-processor
    container_name: waf-realtime-processor
    depends_on:
      kafka:
        condition: service_healthy
      influxdb:
        condition: service_healthy
    environment:
      - KAFKA_BROKERS=kafka:9092
      - KAFKA_TOPIC=waf-realtime-events
      - KAFKA_GROUP=realtime-processor
      - INFLUXDB_URL=http://influxdb:8086
      - INFLUXDB_TOKEN=$(INFLUXDB_TOKEN)
      - INFLUXDB_ORG=waf-org
      - INFLUXDB_BUCKET=waf-realtime
      - INFLUXDB_DUAL_WRITE=true
      - GEOIP_DB_PATH=/data/GeoLite2-City.mmdb
    volumes:
      - ./lib/geoip/GeoLite2-City:/data:ro
    restart: unless-stopped

  # Alert processor
  alert-processor:
    build: ./services/alert-processor
    container_name: waf-alert-processor
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      - KAFKA_BROKERS=kafka:9092
    restart: unless-stopped

  # Grafana
  grafana:
    image: grafana/grafana:10.4.3
    container_name: waf-grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana-data:/var/lib/grafana
    depends_on:
      influxdb:
        condition: service_healthy
    restart: unless-stopped

  # ClickHouse
  clickhouse:
    image: clickhouse/clickhouse-server:23.8-alpine
    container_name: waf-clickhouse
    ports:
      - "8123:8123"
      - "9000:9000"
    environment:
      - CLICKHOUSE_DB=waf_analytics
      - CLICKHOUSE_USER=admin
      - CLICKHOUSE_PASSWORD=adminpassword
    volumes:
      - clickhouse-data:/var/lib/clickhouse
      - ./clickhouse/init.sql:/docker-entrypoint-initdb.d/init.sql:ro
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8123/ping"]
      interval: 10s
      timeout: 5s
      retries: 30

volumes:
  modsec-logs:
  influxdb-data:
  clickhouse-data:
  grafana-data:
  es-data:
  custom-rules-volume: