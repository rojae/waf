# ðŸ›¡ï¸ WAF â€“ Nginx Application Firewall with ModSecurity & OWASP CRS (Not Released)

&#x20;  &#x20;

**Nginx + ModSecurity WAF** powered by the **OWASP ModSecurity Core Rule Set (CRS)**. This repository spins up a full local pipeline with **Filebeat â†’ Kafka â†’ Logstash â†’ Elasticsearch â† Kibana**, plus optional **ksqlDB** for stream processing.

---

## âœ¨ Highlights

- Production-like local stack built with **Docker Compose**
- **KRaft Kafka (no Zookeeper)** with scripted topic bootstrap
- **Filebeat â†’ Kafka **`` (single source of truth)
- **Logstash fanâ€‘out:**
  - Indexes `waf-logs` to **Elasticsearch**
  - **Replicates** the same event to **Kafka **`` (loop-safe)
- Optional **ksqlDB** to derive `enriched`/`metrics` streams
- **Kibana** dashboards for quick exploration

---

## ðŸ“ Architecture

```mermaid
flowchart LR
  classDef svc fill:#e8f1fd,stroke:#4a90e2,color:#0d1a26,stroke-width:1.2,rx:10,ry:10
  classDef db  fill:#e6f7f1,stroke:#28a745,color:#0d1a26,rx:10,ry:10
  classDef vol fill:#fff7e6,stroke:#ffa940,color:#663300,stroke-dasharray:3 3,rx:8,ry:8
  classDef topic fill:#f0f5ff,stroke:#5b8ff9,color:#0d1a26,rx:10,ry:10

  C[Client]:::svc --> N[Nginx_ModSecurity]:::svc
  N --> V[(modsec-logs volume)]:::vol
  V -. ro mount .- F[Filebeat]:::svc
  F -->|produce JSON| T1[[Kafka topic: waf-logs]]:::topic
  K[(Kafka broker)]:::svc --- T1

  subgraph Logstash
    L[logstash]:::svc
  end

  T1 -->|consume| L
  L -->|index| E[Elasticsearch]:::db
  L -->|replicate| T2[[Kafka topic: waf-modsec-raw]]:::topic
  K --- T2

  subgraph Optional/Derived
    T3[[waf-modsec-enriched]]:::topic
    T4[[waf-modsec-metrics]]:::topic
    KSQL[ksqlDB]:::svc
    K --- T3
    K --- T4
    KSQL --- K
  end

  B[Kibana]:::svc -->|visualize| E
```

---

## ðŸ§© Services (container names / ports)

- **waf-nginx** â€“ Nginx + ModSecurity (HTTP: **8080**) writes **ModSecurity JSON logs** to a Docker volume
- **waf-filebeat** â€“ reads the shared volume and publishes to Kafka topic ``
- **waf-kafka** â€“ Apache Kafka (Confluent **7.6.1**, KRaft mode) (**9092**)
- **topics-init** â€“ runs `kafka/ensure-topics.sh` to create topics idempotently
- **waf-ksqldb** â€“ ksqlDB server (**8088**)
- **ksqldb-cli-init** â€“ runs `ksqldb/ddl.sql` and `ksqldb/rulemap-init.sql` after ksqlDB is healthy
- **waf-logstash** â€“ consumes from Kafka, **indexes to ES**, and **fans out** to Kafka `waf-modsec-raw`
- **waf-es** â€“ Elasticsearch **8.15.2** (**9200**)
- **waf-kibana** â€“ Kibana **8.15.2** (**5601**)

---

## ðŸ“¦ Kafka Topics

Created by `kafka/ensure-topics.sh` via the `topics-init` service:

- `waf-logs` (Filebeat â†’ Kafka)
- `waf-modsec-raw` (Logstash fanâ€‘out copy of `waf-logs`)
- `waf-rulemap` (compact; for lookups/joins)
- `waf-modsec-enriched` (derived)
- `waf-modsec-metrics` (derived)

> **Note:** Filebeat canâ€™t publish one event to two topics at once. Thatâ€™s why we fanâ€‘out in **Logstash**.

---

## ðŸš€ Quickstart

### Prerequisites

- Docker 20+
- Docker Compose v2

### Build & Run

```bash
# Build nginx image (uses local Dockerfile)
docker compose build --no-cache

# Start everything
docker compose up -d
```

### Verify health

```bash
# Kafka topics
docker exec -it waf-kafka \
  kafka-topics --bootstrap-server kafka:9092 --list

# ksqlDB info
curl -fsS http://localhost:8088/info | jq .

# Logstash config test
docker exec -it waf-logstash \
  logstash -t -f /usr/share/logstash/pipeline/pipeline.conf
```

### Generate traffic

```bash
curl -i "http://localhost:8080/test.html?q=<script>alert(1)</script>"
```

- Check **Kibana** at [http://localhost:5601](http://localhost:5601)
- Data should appear in indices: `waf-logs-*`, `waf-modsec-raw-*`, and (if enabled) `waf-modsec-enriched-*`, `waf-modsec-metrics-*`

---

## âš™ï¸ Configuration

### Nginx + ModSecurity

- Configs sit under `nginx/` (see `nginx/nginx.conf`, `nginx/modsecurity/*`)
- CRS rules are mounted from this repo (`coreruleset/`)

### Filebeat â†’ Kafka

`filebeat/filebeat.yml` parses JSON, extracts a timestamp (`transaction.time_stamp â†’ ts`), remaps a few fields, and publishes **only** to `waf-logs`:

```yaml
output.kafka:
  hosts: ["kafka:9092"]
  topic: "waf-logs"
  compression: gzip
  required_acks: 1
  codec:
    json:
      pretty: false
      escape_html: false
```

### Logstash (fanâ€‘out + indexing)

- Consumes `waf-logs`, `waf-modsec-raw`, `waf-modsec-enriched`, `waf-modsec-metrics`
- **Fanâ€‘out rule:** when consuming ``, Logstash indexes to ES and **also produces the same event** to Kafka topic ``. It does **not** re-publish anything consumed from `waf-modsec-raw` â†’ no loop.
- Optional: set a consistent partitioning key (e.g., `txId`) via `message_key => "%{txId}"` in the Kafka output.

### ksqlDB

- `ksqldb/ddl.sql` should create streams/tables (DDL only recommended)
- `ksqldb/rulemap-init.sql` may seed data (DML). Both are run by `ksqldb-cli-init` after the server is healthy.
- Handy queries:

```sql
SET 'auto.offset.reset'='earliest';
SELECT * FROM RULEMAP EMIT CHANGES LIMIT 100;
SELECT WINDOWSTART, WINDOWEND, * FROM ATTACKS_BY_IP_1M EMIT CHANGES LIMIT 100;
```

---

## ðŸ“š Directory Structure (excerpt)

```
.
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ nginx/
â”‚   â”œâ”€â”€ nginx.conf
â”‚   â”œâ”€â”€ init.sh
â”‚   â”œâ”€â”€ html/
â”‚   â””â”€â”€ modsecurity/
â”œâ”€â”€ filebeat/
â”‚   â””â”€â”€ filebeat.yml
â”œâ”€â”€ logstash/
â”‚   â””â”€â”€ pipeline/pipeline.conf
â”œâ”€â”€ kafka/
â”‚   â””â”€â”€ ensure-topics.sh
â”œâ”€â”€ ksqldb/
â”‚   â”œâ”€â”€ ddl.sql
â”‚   â””â”€â”€ rulemap-init.sql
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ KAFKA.md
â”‚   â”œâ”€â”€ KIBANA.md
â”‚   â”œâ”€â”€ KSQL.md
â”‚   â””â”€â”€ NGINX.md
â””â”€â”€ TROUBLESHOOTING/
    â”œâ”€â”€ KSQL_INIT.md
    â””â”€â”€ KSQL_JOIN.md
```

---

## ðŸ§ª Testing & Ops Cheatsheet

**Trigger WAF**

```bash
curl -i "http://localhost:8080/?q=<script>alert(1)</script>"
```

**Check Nginx/ModSecurity logs**

```bash
docker logs waf-nginx
Docker exec -it waf-nginx sh -lc 'tail -n 100 /var/log/modsecurity/*.log'
```

**Watch Kafka topics**

```bash
docker exec -it waf-kafka \
  kafka-console-consumer --bootstrap-server kafka:9092 \
  --topic waf-logs --from-beginning --timeout-ms 5000
```

**Kibana**

- [http://localhost:5601](http://localhost:5601)
- Create data views: `waf-logs-*`, `waf-modsec-raw-*`, `waf-modsec-enriched-*`, `waf-modsec-metrics-*`

---

## ðŸ§± (Optional) Index Template for ES - (Not Implementes)

Lock down important field types to avoid mapping conflicts:

```json
PUT _index_template/waf-template
{
  "index_patterns": [
    "waf-logs-*",
    "waf-modsec-raw-*",
    "waf-modsec-enriched-*",
    "waf-modsec-metrics-*"
  ],
  "template": {
    "settings": { "number_of_shards": 1, "number_of_replicas": 0 },
    "mappings": {
      "dynamic": true,
      "properties": {
        "@timestamp": { "type": "date" },
        "status": { "type": "integer" },
        "anomalyScore": { "type": "integer" },
        "txId": { "type": "keyword" },
        "rule": { "properties": { "id": { "type": "keyword" } } },
        "source": { "properties": { "ip": { "type": "ip" } } },
        "url": {
          "properties": {
            "domain": { "type": "keyword" },
            "path": { "type": "keyword" }
          }
        },
        "event": { "properties": { "category": { "type": "keyword" }, "kind": { "type": "keyword" } } },
        "observer": { "properties": { "type": { "type": "keyword" }, "name": { "type": "keyword" } } },
        "labels": { "properties": { "tenant": { "type": "keyword" } } },
        "message": { "type": "text" }
      }
    }
  },
  "priority": 200
}
```

---

## ðŸ©º Troubleshooting

- **Logstash config parse errors**: the DSL does **not** support semicolons `;`. Split plugin options by newline/spaces. Test with:
  ```bash
  docker exec -it waf-logstash logstash -t -f /usr/share/logstash/pipeline/pipeline.conf
  ```
- **Filebeat to two topics?** Not supported. Use **Logstash fanâ€‘out** (already configured) or run a second Filebeat instance (not recommended).
- ``** field rename conflicts**: Beats often send `host.*` as an object. If you need `url.domain`, copy from `host.name` instead of renaming the whole `host` object.
- **Time zones & index date**: index suffixes are based on `@timestamp`. In this repo, date filters set `UTC` (you can change if you want KST-based cuts).

---

## ðŸ”’ License & Credits

- MIT License (see `License.md`)
- CRS: [https://github.com/coreruleset/coreruleset](https://github.com/coreruleset/coreruleset)
- ModSecurity: [https://github.com/SpiderLabs/ModSecurity](https://github.com/SpiderLabs/ModSecurity)
- Nikto: [https://github.com/sullo/nikto](https://github.com/sullo/nikto)